{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ee0a2a",
   "metadata": {},
   "source": [
    "# Assignement : PageRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import matrix\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c98192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.38709677],\n",
       "        [0.12903226],\n",
       "        [0.29032258],\n",
       "        [0.19354839]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "T = matrix([\n",
    "    [0, 0, 1, 1/2],\n",
    "    [1/3, 0, 0, 0],\n",
    "    [1/3, 1/2, 0, 1/2],\n",
    "    [1/3, 1/2, 0, 0],\n",
    "])\n",
    "p = matrix([[1/4], [1/4], [1/4], [1/4]])\n",
    "for i in range(100):\n",
    "   p = T*p\n",
    "p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbf415",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8386bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de noeuds : 199903\n"
     ]
    }
   ],
   "source": [
    "# la matrice T pour le snapshot de wikipedia sera gigantesque mais avec plein de 0\n",
    "# Donc on va juste récupérer les points d'intéret du style ((1,4,1/2), (2,1,1/3))\n",
    "# utiliser pandas pour lire le csv.\n",
    "# faire la boucle for avec numpy parce qu'il utilise du c++ (plus rapide) et les fichiers csv sont gros.\n",
    "# proposition : probabilité après k+1 = stochastic \n",
    "\n",
    "\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "\n",
    "names = pd.read_csv(\"wikidata/names.csv\")\n",
    "edges = pd.read_csv(\"wikidata/edges.csv\")\n",
    "\n",
    "# Récupération de tout les id, entrant comme sortant.\n",
    "all_ids = pd.concat([edges[\"FromNode\"], edges[\"ToNode\"]]).unique()\n",
    "id_to_idx = {node_id: i for i, node_id in enumerate(all_ids)}\n",
    "N = len(all_ids)\n",
    "\n",
    "\n",
    "print(\"Nombre de noeuds :\", N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380d7822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f : 175973  t : 1  rows : [38619]  cols : [0]  data : [np.float64(0.025)]\n",
      "f : 130880  t : 2  rows : [38619, 52918]  cols : [0, 1]  data : [np.float64(0.025), np.float64(0.007936507936507936)]\n",
      "f : 145856  t : 2  rows : [38619, 52918, 52918]  cols : [0, 1, 2]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266)]\n",
      "f : 159190  t : 2  rows : [38619, 52918, 52918, 52918]  cols : [0, 1, 2, 3]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625)]\n",
      "f : 159200  t : 2  rows : [38619, 52918, 52918, 52918, 52918]  cols : [0, 1, 2, 3, 4]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625), np.float64(0.017543859649122806)]\n",
      "f : 159207  t : 2  rows : [38619, 52918, 52918, 52918, 52918, 52918]  cols : [0, 1, 2, 3, 4, 5]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625), np.float64(0.017543859649122806), np.float64(0.02564102564102564)]\n",
      "f : 159431  t : 2  rows : [38619, 52918, 52918, 52918, 52918, 52918, 52918]  cols : [0, 1, 2, 3, 4, 5, 6]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625), np.float64(0.017543859649122806), np.float64(0.02564102564102564), np.float64(0.0037174721189591076)]\n",
      "f : 4  t : 3  rows : [38619, 52918, 52918, 52918, 52918, 52918, 52918, 63]  cols : [0, 1, 2, 3, 4, 5, 6, 7]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625), np.float64(0.017543859649122806), np.float64(0.02564102564102564), np.float64(0.0037174721189591076), np.float64(0.07692307692307693)]\n",
      "f : 5  t : 3  rows : [38619, 52918, 52918, 52918, 52918, 52918, 52918, 63, 63]  cols : [0, 1, 2, 3, 4, 5, 6, 7, 8]  data : [np.float64(0.025), np.float64(0.007936507936507936), np.float64(0.012658227848101266), np.float64(0.0625), np.float64(0.017543859649122806), np.float64(0.02564102564102564), np.float64(0.0037174721189591076), np.float64(0.07692307692307693), np.float64(0.08333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- CONSTRUCTION DE LA MATRICE DE TRANSITION SPARSE ---\n",
    "\n",
    "# On calcule le nombre de liens sortants pour normaliser les appels vers une page\n",
    "out_degree = edges[\"FromNode\"].value_counts()\n",
    "\n",
    "rows = []   # lignes = destinations (ToNode)\n",
    "cols = []   # colonnes = sources (FromNode)\n",
    "data = []   # valeurs = 1/out_degree\n",
    "\n",
    "for f, t in zip(edges[\"FromNode\"], edges[\"ToNode\"]):\n",
    "    cols.append(id_to_idx[f])\n",
    "    rows.append(id_to_idx[t])\n",
    "    data.append(1.0 / out_degree[f])\n",
    "    if len(cols) < 10:\n",
    "        print(\"f :\", f, \" t :\", t, \" rows :\", rows, \" cols :\", cols, \" data :\", data )\n",
    "\n",
    "# Construction de la matrice T en format sparse CSR\n",
    "T = coo_matrix((data, (rows, cols)), shape=(N, N)).tocsr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05419f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb3e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. United States — score 0.002348\n",
      "2. United Kingdom — score 0.001282\n",
      "3. World War II — score 0.001051\n",
      "4. France — score 0.000990\n",
      "5. Latin — score 0.000853\n",
      "6. Germany — score 0.000847\n",
      "7. Canada — score 0.000729\n",
      "8. English language — score 0.000695\n",
      "9. China — score 0.000694\n",
      "10. India — score 0.000679\n",
      "11. Italy — score 0.000657\n",
      "12. Catholic Church — score 0.000625\n",
      "13. Australia — score 0.000623\n",
      "14. England — score 0.000621\n",
      "15. World War I — score 0.000579\n",
      "16. London — score 0.000572\n",
      "17. Europe — score 0.000568\n",
      "18. Mathematics — score 0.000553\n",
      "19. Russia — score 0.000521\n",
      "20. Greek language — score 0.000509\n",
      "21. Japan — score 0.000491\n",
      "22. New York City — score 0.000485\n",
      "23. Soviet Union — score 0.000468\n",
      "24. French language — score 0.000452\n",
      "25. Spain — score 0.000448\n",
      "26. Netherlands — score 0.000429\n",
      "27. Paris — score 0.000418\n",
      "28. Middle Ages — score 0.000405\n",
      "29. European Union — score 0.000390\n",
      "30. Washington, D.C. — score 0.000385\n",
      "31. Scotland — score 0.000369\n",
      "32. New York — score 0.000346\n",
      "33. California — score 0.000341\n",
      "34. Egypt — score 0.000337\n",
      "35. German language — score 0.000337\n",
      "36. Roman Empire — score 0.000336\n",
      "37. New Zealand — score 0.000329\n",
      "38. United Nations — score 0.000323\n",
      "39. Sweden — score 0.000321\n",
      "40. Switzerland — score 0.000317\n",
      "41. Poland — score 0.000313\n",
      "42. Rome — score 0.000304\n",
      "43. Islam — score 0.000304\n",
      "44. The New York Times — score 0.000302\n",
      "45. North America — score 0.000302\n",
      "46. Brazil — score 0.000301\n",
      "47. Iran — score 0.000300\n",
      "48. Arabic language — score 0.000296\n",
      "49. Turkey — score 0.000295\n",
      "50. Israel — score 0.000293\n",
      "51. Christianity — score 0.000292\n",
      "52. Belgium — score 0.000289\n",
      "53. Mexico — score 0.000286\n",
      "54. Association football — score 0.000285\n",
      "55. Greece — score 0.000281\n",
      "56. United States dollar — score 0.000280\n",
      "57. Spanish language — score 0.000278\n",
      "58. Ottoman Empire — score 0.000277\n",
      "59. Ancient Rome — score 0.000270\n",
      "60. President of the United States — score 0.000268\n",
      "61. Physics — score 0.000268\n",
      "62. Austria — score 0.000263\n",
      "63. South Africa — score 0.000261\n",
      "64. Portugal — score 0.000256\n",
      "65. Ireland — score 0.000253\n",
      "66. Animal — score 0.000250\n",
      "67. United States Congress — score 0.000250\n",
      "68. Buddhism — score 0.000246\n",
      "69. Protestantism — score 0.000245\n",
      "70. Jews — score 0.000243\n",
      "71. Ancient Greek — score 0.000243\n",
      "72. Philippines — score 0.000242\n",
      "73. Denmark — score 0.000240\n",
      "74. Pakistan — score 0.000240\n",
      "75. Protein — score 0.000239\n",
      "76. Africa — score 0.000236\n",
      "77. Norway — score 0.000235\n",
      "78. Byzantine Empire — score 0.000235\n",
      "79. American Civil War — score 0.000229\n",
      "80. BBC — score 0.000229\n",
      "81. Taiwan — score 0.000227\n",
      "82. Asia — score 0.000224\n",
      "83. Indonesia — score 0.000223\n",
      "84. Sanskrit — score 0.000223\n",
      "85. Oxygen — score 0.000223\n",
      "86. Chicago — score 0.000217\n",
      "87. United States Senate — score 0.000215\n",
      "88. Economics — score 0.000215\n",
      "89. Supreme Court of the United States — score 0.000214\n",
      "90. Eastern Orthodox Church — score 0.000213\n",
      "91. Philosophy — score 0.000211\n",
      "92. Ancient Greece — score 0.000211\n",
      "93. Law — score 0.000210\n",
      "94. Plant — score 0.000208\n",
      "95. Nazi Germany — score 0.000207\n",
      "96. U.S. state — score 0.000207\n",
      "97. Finland — score 0.000207\n",
      "98. French Revolution — score 0.000205\n",
      "99. Argentina — score 0.000203\n",
      "100. Harvard University — score 0.000202\n"
     ]
    }
   ],
   "source": [
    "# --- PAGE RANK ---\n",
    "\n",
    "alpha = 0.85\n",
    "p = np.ones(N) / N\n",
    "teleport = (1 - alpha) / N\n",
    "\n",
    "for _ in range(110):  # converge généralement avant\n",
    "    p = alpha * (T @ p) + teleport\n",
    "\n",
    "# --- EXTRACTION DES TOP PAGES ---\n",
    "\n",
    "top_k = 100\n",
    "top_idx = np.argsort(-p)[:top_k]\n",
    "\n",
    "for rank, idx in enumerate(top_idx, 1):\n",
    "    original_id = all_ids[idx]\n",
    "    if original_id < len(names):\n",
    "        name = names.iloc[original_id-1][\"Name\"]\n",
    "    else:\n",
    "        name = \"(unknown)\"\n",
    "    print(f\"{rank}. {name} — score {p[idx]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de noeuds : 199903\n",
      "1. Hollywood Bowl — score 0.002348\n",
      "2. The Independent — score 0.001282\n",
      "3. Phoney War — score 0.001051\n",
      "4. INSEE code — score 0.000990\n",
      "5. Unclean animal — score 0.000853\n",
      "6. Brandenburg an der Havel — score 0.000847\n",
      "7. George A. Drew — score 0.000729\n",
      "8. United Nations in popular culture — score 0.000695\n",
      "9. Sichuan Basin — score 0.000694\n",
      "10. Non-resident Indian and person of Indian origin — score 0.000679\n",
      "11. Paolo Rossi — score 0.000657\n",
      "12. Roman Catholic Archdiocese of Berlin — score 0.000625\n",
      "13. Aboriginal Australians — score 0.000623\n",
      "14. Terry Venables — score 0.000621\n",
      "15. Northwood Headquarters — score 0.000579\n",
      "16. Hyde Park, London — score 0.000572\n",
      "17. Codling moth — score 0.000568\n",
      "18. Function (mathematics) — score 0.000553\n",
      "19. Volga Federal District — score 0.000521\n",
      "20. Lacuna (manuscripts) — score 0.000509\n"
     ]
    }
   ],
   "source": [
    "# la matrice T pour le snapshot de wikipedia sera gigantesque mais avec plein de 0\n",
    "# Donc on va juste récupérer les points d'intéret du style ((1,4,1/2), (2,1,1/3))\n",
    "# utiliser pandas pour lire le csv.\n",
    "# faire la boucle for avec numpy parce qu'il utilise du c++ (plus rapide) et les fichiers csv sont gros.\n",
    "# proposition : probabilité après k+1 = stochastic \n",
    "\n",
    "# ==== CODE FINAL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "\n",
    "names = pd.read_csv(\"wikidata/names.csv\")\n",
    "edges = pd.read_csv(\"wikidata/edges.csv\")\n",
    "\n",
    "# Récupération de tout les id, entrant comme sortant.\n",
    "all_ids = pd.concat([edges[\"FromNode\"], edges[\"ToNode\"]]).unique()\n",
    "id_to_idx = {node_id: i for i, node_id in enumerate(all_ids)}\n",
    "N = len(all_ids)\n",
    "\n",
    "\n",
    "print(\"Nombre de noeuds :\", N)\n",
    "\n",
    "\n",
    "# --- CONSTRUCTION DE LA MATRICE DE TRANSITION SPARSE ---\n",
    "\n",
    "# On calcule le nombre de liens sortants pour normaliser les appels vers une page\n",
    "out_degree = edges[\"FromNode\"].value_counts()\n",
    "\n",
    "rows = []   # lignes = destinations (ToNode)\n",
    "cols = []   # colonnes = sources (FromNode)\n",
    "data = []   # valeurs = 1/out_degree\n",
    "\n",
    "for f, t in zip(edges[\"FromNode\"], edges[\"ToNode\"]):\n",
    "    cols.append(id_to_idx[f])\n",
    "    rows.append(id_to_idx[t])\n",
    "    data.append(1.0 / out_degree[f])\n",
    "    if len(cols) < 10:\n",
    "        print(\"f :\", f, \" t :\", t, \" rows :\", rows, \" cols :\", cols, \" data :\", data )\n",
    "\n",
    "# Construction de la matrice T en format sparse CSR\n",
    "T = coo_matrix((data, (rows, cols)), shape=(N, N)).tocsr()\n",
    "\n",
    "\n",
    "\n",
    "# --- PAGE RANK ---\n",
    "\n",
    "alpha = 0.85\n",
    "p = np.ones(N) / N\n",
    "teleport = (1 - alpha) / N\n",
    "\n",
    "for _ in range(110):  # converge généralement avant\n",
    "    p = alpha * (T @ p) + teleport\n",
    "\n",
    "# --- EXTRACTION DES TOP PAGES ---\n",
    "\n",
    "top_k = 100\n",
    "top_idx = np.argsort(-p)[:top_k]\n",
    "\n",
    "for rank, idx in enumerate(top_idx, 1):\n",
    "    original_id = all_ids[idx]\n",
    "    if original_id < len(names):\n",
    "        name = names.iloc[original_id-1][\"Name\"]\n",
    "    else:\n",
    "        name = \"(unknown)\"\n",
    "    print(f\"{rank}. {name} — score {p[idx]:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
